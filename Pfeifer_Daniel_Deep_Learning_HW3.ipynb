{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Homework 3\n",
    "**Pfeifer Dániel<br>\n",
    "N65V6V**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to create a Neural Network that can predict the average temperature on a given day in Budapest. I have used the Minimum and Maximum temperatures recorded from 2018 October 2nd to 2020 October 25th (yesterday) - around 2 years worth of data. This can be found here: http://idojarasbudapest.hu/archivalt-idojaras\n",
    "\n",
    "I have also complied a database containing the data from the website, which can be found along with this Notebook on GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "from datetime import date\n",
    "import calendar\n",
    "import matplotlib.pyplot as plt\n",
    "random_state = 5555"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First I load in the database.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>Tmax</th>\n",
       "      <th>Tmin</th>\n",
       "      <th>wind</th>\n",
       "      <th>precip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-10-02 00:00:00</td>\n",
       "      <td>14.3</td>\n",
       "      <td>6.8</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kedd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-10-03 00:00:00</td>\n",
       "      <td>16.8</td>\n",
       "      <td>3.5</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>szerda</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-10-04 00:00:00</td>\n",
       "      <td>15.7</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1505</th>\n",
       "      <td>péntek</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1506</th>\n",
       "      <td>2020-10-24 00:00:00</td>\n",
       "      <td>17.9</td>\n",
       "      <td>12.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>szombat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508</th>\n",
       "      <td>2020-10-25 00:00:00</td>\n",
       "      <td>13.3</td>\n",
       "      <td>12.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>vasárnap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1510 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      day  Tmax  Tmin  wind  precip\n",
       "0     2018-10-02 00:00:00  14.3   6.8   6.3     0.8\n",
       "1                    kedd   NaN   NaN   NaN     NaN\n",
       "2     2018-10-03 00:00:00  16.8   3.5   7.4     0.1\n",
       "3                  szerda   NaN   NaN   NaN     NaN\n",
       "4     2018-10-04 00:00:00  15.7   5.7   4.3     0.0\n",
       "...                   ...   ...   ...   ...     ...\n",
       "1505               péntek   NaN   NaN   NaN     NaN\n",
       "1506  2020-10-24 00:00:00  17.9  12.1   5.6     0.0\n",
       "1507              szombat   NaN   NaN   NaN     NaN\n",
       "1508  2020-10-25 00:00:00  13.3  12.9   2.3     4.5\n",
       "1509             vasárnap   NaN   NaN   NaN     NaN\n",
       "\n",
       "[1510 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_base = pd.read_excel(\"./weather.xlsx\", header=None, names=['day','Tmax','Tmin','wind','precip'])\n",
    "weather_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**However, it's not quite in a usable format, so I'm transforming it.**\n",
    "- I'm removing every second row,\n",
    "- Adding an `ID`,\n",
    "- Adding a `month` variable that I'll later use as a predictor variable.\n",
    "- And I'm only using the `Tmin` and `Tmax` columns. (Omitting the columns containing `wind` and `precipitation` values. - Though perhaps a better prediction could have been gotten if I used them.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = []\n",
    "date_list = []\n",
    "month_list = []\n",
    "Tmin_list = []\n",
    "Tmax_list = []\n",
    "counter = 0\n",
    "for i, row in weather_base.iterrows():\n",
    "    if i % 2 == 0:\n",
    "        id_list.append(counter)\n",
    "        counter += 1\n",
    "        date_list.append(row['day'])\n",
    "        month_list.append(row['day'].month)\n",
    "        Tmin_list.append(row['Tmin'])\n",
    "        Tmax_list.append(row['Tmax'])\n",
    "weather = pd.DataFrame(data={'id':id_list,'date':date_list,'month':month_list,\n",
    "                             'Tmin':Tmin_list, 'Tmax':Tmax_list})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now it seems quite a but more usable:**\n",
    "\n",
    "**Note:** Our goal is to predict the **average** temperature, which is by definition $\\frac{\\text{Tmin}+\\text{Tmax}}{2}$. This can obvously be gotten from our predictions later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>Tmin</th>\n",
       "      <th>Tmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-10-02</td>\n",
       "      <td>10</td>\n",
       "      <td>6.8</td>\n",
       "      <td>14.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>10</td>\n",
       "      <td>3.5</td>\n",
       "      <td>16.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-10-04</td>\n",
       "      <td>10</td>\n",
       "      <td>5.7</td>\n",
       "      <td>15.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-10-05</td>\n",
       "      <td>10</td>\n",
       "      <td>2.9</td>\n",
       "      <td>17.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-10-06</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>750</td>\n",
       "      <td>2020-10-21</td>\n",
       "      <td>10</td>\n",
       "      <td>8.9</td>\n",
       "      <td>16.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>751</td>\n",
       "      <td>2020-10-22</td>\n",
       "      <td>10</td>\n",
       "      <td>10.3</td>\n",
       "      <td>15.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>752</td>\n",
       "      <td>2020-10-23</td>\n",
       "      <td>10</td>\n",
       "      <td>10.8</td>\n",
       "      <td>16.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>753</td>\n",
       "      <td>2020-10-24</td>\n",
       "      <td>10</td>\n",
       "      <td>12.1</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>754</td>\n",
       "      <td>2020-10-25</td>\n",
       "      <td>10</td>\n",
       "      <td>12.9</td>\n",
       "      <td>13.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>755 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id       date  month  Tmin  Tmax\n",
       "0      0 2018-10-02     10   6.8  14.3\n",
       "1      1 2018-10-03     10   3.5  16.8\n",
       "2      2 2018-10-04     10   5.7  15.7\n",
       "3      3 2018-10-05     10   2.9  17.1\n",
       "4      4 2018-10-06     10   4.0  20.3\n",
       "..   ...        ...    ...   ...   ...\n",
       "750  750 2020-10-21     10   8.9  16.6\n",
       "751  751 2020-10-22     10  10.3  15.7\n",
       "752  752 2020-10-23     10  10.8  16.4\n",
       "753  753 2020-10-24     10  12.1  17.9\n",
       "754  754 2020-10-25     10  12.9  13.3\n",
       "\n",
       "[755 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Each row of the **predictor varables** will contain 4 consecutive rows of our original database, flattened out into $[month_1,Tmin_1,Tmax_1,\\dots,month_4,Tmin_4,Tmax_4]$, which is exactly 12 values per row.\n",
    "- Each row of the **output variables** will contain the lowest and highest temperatures of the following day: $[Tmin_5,Tmax_5]$.\n",
    "- This way our predictor has access to temperatures of the previous 4 days, and knows generally what season we're currently in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for i, row in weather.iterrows():\n",
    "    if i < len(weather)-4:\n",
    "        current_X_element = []\n",
    "        for j in range(4):\n",
    "            cur_row = weather[i+j:i+j+1]\n",
    "            current_X_element.append(int(cur_row['month']))\n",
    "            current_X_element.append(float(cur_row['Tmin']))\n",
    "            current_X_element.append(float(cur_row['Tmax']))\n",
    "        X.append(current_X_element)\n",
    "        cur_target_row = weather[i+4:i+5]\n",
    "        y.append([float(cur_target_row['Tmin']),\n",
    "                  float(cur_target_row['Tmax'])])\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our predictor variables are the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10. ,  6.8, 14.3, ..., 10. ,  2.9, 17.1],\n",
       "       [10. ,  3.5, 16.8, ..., 10. ,  4. , 20.3],\n",
       "       [10. ,  5.7, 15.7, ..., 10. , 12.7, 20.3],\n",
       "       ...,\n",
       "       [10. ,  8. , 14.1, ..., 10. , 10.3, 15.7],\n",
       "       [10. ,  9.6, 14.8, ..., 10. , 10.8, 16.4],\n",
       "       [10. ,  8.9, 16.6, ..., 10. , 12.1, 17.9]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "751 rows and 12 columns (as I've described earlier):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(751, 12)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And our output variables are the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4. , 20.3],\n",
       "       [12.7, 20.3],\n",
       "       [11.9, 19.6],\n",
       "       ...,\n",
       "       [10.8, 16.4],\n",
       "       [12.1, 17.9],\n",
       "       [12.9, 13.3]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also 751 rows and 2 columns (minimum and maximum temperatures on the given day):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(751, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these, I'll use `sklearn`'s `train_test_split` method to split them randomly into 70% (Train set) and 30% (Test set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train:  (525, 12)\n",
      "Shape of X_test:  (226, 12)\n",
      "Shape of y_train:  (525, 2)\n",
      "Shape of y_test:  (226, 2)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_state)\n",
    "print(\"Shape of X_train: \", X_train.shape)\n",
    "print(\"Shape of X_test: \", X_test.shape)\n",
    "print(\"Shape of y_train: \", y_train.shape)\n",
    "print(\"Shape of y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Building the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm defining a **Dense Layer** which I'll use multiple times, with:\n",
    "- 0.01 L1 kernel regularization, and\n",
    "- RELU activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_layer(output_size):\n",
    "    return tf.keras.layers.Dense(output_size,\n",
    "                                kernel_regularizer=tf.keras.regularizers.l1(0.01),\n",
    "                                activation='relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual **Neural Network** is made up of:\n",
    "- simply 3 of these layers with an input and output size if 12,\n",
    "- then a final layer with an input size of 12, and an output size of 2 nodes;\n",
    "- it's using `sklearn`'s `Adam` optimizer,\n",
    "- and the loss function is simply the Mean Squared Error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\AMD\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(dense_layer(12))\n",
    "model.add(dense_layer(12))\n",
    "model.add(dense_layer(12))\n",
    "model.add(tf.keras.layers.Dense(2))\n",
    "model.compile(optimizer='Adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Them I'm fitting the model for the previously definied `X_train` and `y_train` variables, with:\n",
    "- a batch size of 20,\n",
    "- and 100 epochs, which might seem like a lot, however from my testing it seemed it was still learning even after 70-80 epochs, and not overfitting. Besides, the model is very simple and runs pretty fast even with 100 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "525/525 [==============================] - 0s 668us/sample - loss: 246.9560\n",
      "Epoch 2/100\n",
      "525/525 [==============================] - 0s 71us/sample - loss: 117.7013\n",
      "Epoch 3/100\n",
      "525/525 [==============================] - 0s 69us/sample - loss: 39.2453\n",
      "Epoch 4/100\n",
      "525/525 [==============================] - 0s 67us/sample - loss: 16.4689\n",
      "Epoch 5/100\n",
      "525/525 [==============================] - 0s 65us/sample - loss: 15.2675\n",
      "Epoch 6/100\n",
      "525/525 [==============================] - 0s 71us/sample - loss: 14.5780\n",
      "Epoch 7/100\n",
      "525/525 [==============================] - 0s 73us/sample - loss: 13.9368\n",
      "Epoch 8/100\n",
      "525/525 [==============================] - 0s 67us/sample - loss: 13.4666\n",
      "Epoch 9/100\n",
      "525/525 [==============================] - 0s 69us/sample - loss: 13.0079\n",
      "Epoch 10/100\n",
      "525/525 [==============================] - 0s 76us/sample - loss: 12.5685\n",
      "Epoch 11/100\n",
      "525/525 [==============================] - 0s 73us/sample - loss: 12.1295\n",
      "Epoch 12/100\n",
      "525/525 [==============================] - 0s 74us/sample - loss: 11.6654\n",
      "Epoch 13/100\n",
      "525/525 [==============================] - 0s 78us/sample - loss: 11.2024\n",
      "Epoch 14/100\n",
      "525/525 [==============================] - 0s 80us/sample - loss: 10.6850\n",
      "Epoch 15/100\n",
      "525/525 [==============================] - 0s 89us/sample - loss: 10.3276\n",
      "Epoch 16/100\n",
      "525/525 [==============================] - 0s 71us/sample - loss: 9.9522\n",
      "Epoch 17/100\n",
      "525/525 [==============================] - 0s 69us/sample - loss: 9.7630\n",
      "Epoch 18/100\n",
      "525/525 [==============================] - 0s 71us/sample - loss: 9.3600\n",
      "Epoch 19/100\n",
      "525/525 [==============================] - 0s 74us/sample - loss: 8.9110\n",
      "Epoch 20/100\n",
      "525/525 [==============================] - 0s 73us/sample - loss: 8.8167\n",
      "Epoch 21/100\n",
      "525/525 [==============================] - 0s 73us/sample - loss: 8.2527\n",
      "Epoch 22/100\n",
      "525/525 [==============================] - 0s 71us/sample - loss: 8.0830\n",
      "Epoch 23/100\n",
      "525/525 [==============================] - 0s 67us/sample - loss: 7.7130\n",
      "Epoch 24/100\n",
      "525/525 [==============================] - 0s 67us/sample - loss: 7.6263\n",
      "Epoch 25/100\n",
      "525/525 [==============================] - 0s 63us/sample - loss: 7.5466\n",
      "Epoch 26/100\n",
      "525/525 [==============================] - 0s 71us/sample - loss: 7.3571\n",
      "Epoch 27/100\n",
      "525/525 [==============================] - 0s 67us/sample - loss: 7.3308\n",
      "Epoch 28/100\n",
      "525/525 [==============================] - 0s 67us/sample - loss: 7.1385\n",
      "Epoch 29/100\n",
      "525/525 [==============================] - 0s 67us/sample - loss: 7.1051\n",
      "Epoch 30/100\n",
      "525/525 [==============================] - 0s 69us/sample - loss: 7.0206\n",
      "Epoch 31/100\n",
      "525/525 [==============================] - 0s 67us/sample - loss: 7.1012\n",
      "Epoch 32/100\n",
      "525/525 [==============================] - 0s 67us/sample - loss: 6.9521\n",
      "Epoch 33/100\n",
      "525/525 [==============================] - 0s 65us/sample - loss: 6.9029\n",
      "Epoch 34/100\n",
      "525/525 [==============================] - 0s 71us/sample - loss: 6.8709\n",
      "Epoch 35/100\n",
      "525/525 [==============================] - 0s 67us/sample - loss: 7.0092\n",
      "Epoch 36/100\n",
      "525/525 [==============================] - 0s 69us/sample - loss: 6.8180\n",
      "Epoch 37/100\n",
      "525/525 [==============================] - 0s 65us/sample - loss: 6.7683\n",
      "Epoch 38/100\n",
      "525/525 [==============================] - 0s 71us/sample - loss: 6.9482\n",
      "Epoch 39/100\n",
      "525/525 [==============================] - 0s 69us/sample - loss: 6.7579\n",
      "Epoch 40/100\n",
      "525/525 [==============================] - 0s 67us/sample - loss: 6.8177\n",
      "Epoch 41/100\n",
      "525/525 [==============================] - 0s 67us/sample - loss: 6.7249\n",
      "Epoch 42/100\n",
      "525/525 [==============================] - 0s 71us/sample - loss: 6.6729\n",
      "Epoch 43/100\n",
      "525/525 [==============================] - 0s 67us/sample - loss: 6.7021\n",
      "Epoch 44/100\n",
      "525/525 [==============================] - 0s 73us/sample - loss: 6.7519\n",
      "Epoch 45/100\n",
      "525/525 [==============================] - 0s 67us/sample - loss: 6.6607\n",
      "Epoch 46/100\n",
      "525/525 [==============================] - 0s 67us/sample - loss: 6.6107\n",
      "Epoch 47/100\n",
      "525/525 [==============================] - 0s 67us/sample - loss: 6.6586\n",
      "Epoch 48/100\n",
      "525/525 [==============================] - 0s 65us/sample - loss: 6.6128\n",
      "Epoch 49/100\n",
      "525/525 [==============================] - 0s 71us/sample - loss: 6.6122\n",
      "Epoch 50/100\n",
      "525/525 [==============================] - 0s 69us/sample - loss: 6.5853\n",
      "Epoch 51/100\n",
      "525/525 [==============================] - 0s 65us/sample - loss: 6.9102\n",
      "Epoch 52/100\n",
      "525/525 [==============================] - 0s 67us/sample - loss: 6.6751\n",
      "Epoch 53/100\n",
      "525/525 [==============================] - 0s 74us/sample - loss: 6.6718\n",
      "Epoch 54/100\n",
      "525/525 [==============================] - 0s 67us/sample - loss: 6.6399\n",
      "Epoch 55/100\n",
      "525/525 [==============================] - 0s 67us/sample - loss: 6.8189\n",
      "Epoch 56/100\n",
      "525/525 [==============================] - 0s 71us/sample - loss: 6.5470\n",
      "Epoch 57/100\n",
      "525/525 [==============================] - 0s 65us/sample - loss: 6.5483\n",
      "Epoch 58/100\n",
      "525/525 [==============================] - 0s 67us/sample - loss: 6.4351\n",
      "Epoch 59/100\n",
      "525/525 [==============================] - 0s 63us/sample - loss: 6.4371\n",
      "Epoch 60/100\n",
      "525/525 [==============================] - 0s 71us/sample - loss: 6.4527\n",
      "Epoch 61/100\n",
      "525/525 [==============================] - 0s 65us/sample - loss: 6.4158\n",
      "Epoch 62/100\n",
      "525/525 [==============================] - 0s 63us/sample - loss: 6.6304\n",
      "Epoch 63/100\n",
      "525/525 [==============================] - 0s 65us/sample - loss: 6.4317\n",
      "Epoch 64/100\n",
      "525/525 [==============================] - 0s 67us/sample - loss: 6.5612\n",
      "Epoch 65/100\n",
      "525/525 [==============================] - 0s 65us/sample - loss: 6.4417\n",
      "Epoch 66/100\n",
      "525/525 [==============================] - 0s 65us/sample - loss: 6.3808\n",
      "Epoch 67/100\n",
      "525/525 [==============================] - 0s 65us/sample - loss: 6.3526\n",
      "Epoch 68/100\n",
      "525/525 [==============================] - 0s 67us/sample - loss: 6.4054\n",
      "Epoch 69/100\n",
      "525/525 [==============================] - 0s 67us/sample - loss: 6.3358\n",
      "Epoch 70/100\n",
      "525/525 [==============================] - 0s 69us/sample - loss: 6.2989\n",
      "Epoch 71/100\n",
      "525/525 [==============================] - 0s 67us/sample - loss: 6.3370\n",
      "Epoch 72/100\n",
      "525/525 [==============================] - 0s 65us/sample - loss: 6.4447\n",
      "Epoch 73/100\n",
      "525/525 [==============================] - 0s 65us/sample - loss: 6.3877\n",
      "Epoch 74/100\n",
      "525/525 [==============================] - 0s 67us/sample - loss: 6.2753\n",
      "Epoch 75/100\n",
      "525/525 [==============================] - 0s 63us/sample - loss: 6.3744\n",
      "Epoch 76/100\n",
      "525/525 [==============================] - 0s 65us/sample - loss: 6.4060\n",
      "Epoch 77/100\n",
      "525/525 [==============================] - 0s 65us/sample - loss: 6.2437\n",
      "Epoch 78/100\n",
      "525/525 [==============================] - 0s 65us/sample - loss: 6.2819\n",
      "Epoch 79/100\n",
      "525/525 [==============================] - 0s 65us/sample - loss: 6.4812\n",
      "Epoch 80/100\n",
      "525/525 [==============================] - 0s 63us/sample - loss: 6.3300\n",
      "Epoch 81/100\n",
      "525/525 [==============================] - 0s 65us/sample - loss: 6.2953\n",
      "Epoch 82/100\n",
      "525/525 [==============================] - 0s 63us/sample - loss: 6.2151\n",
      "Epoch 83/100\n",
      "525/525 [==============================] - 0s 65us/sample - loss: 6.2459\n",
      "Epoch 84/100\n",
      "525/525 [==============================] - 0s 67us/sample - loss: 6.2017\n",
      "Epoch 85/100\n",
      "525/525 [==============================] - 0s 65us/sample - loss: 6.1809\n",
      "Epoch 86/100\n",
      "525/525 [==============================] - 0s 65us/sample - loss: 6.1942\n",
      "Epoch 87/100\n",
      "525/525 [==============================] - 0s 65us/sample - loss: 6.2985\n",
      "Epoch 88/100\n",
      "525/525 [==============================] - 0s 63us/sample - loss: 6.1536\n",
      "Epoch 89/100\n",
      "525/525 [==============================] - 0s 67us/sample - loss: 6.3573\n",
      "Epoch 90/100\n",
      "525/525 [==============================] - 0s 65us/sample - loss: 6.1822\n",
      "Epoch 91/100\n",
      "525/525 [==============================] - 0s 67us/sample - loss: 6.1432\n",
      "Epoch 92/100\n",
      "525/525 [==============================] - 0s 65us/sample - loss: 6.2389\n",
      "Epoch 93/100\n",
      "525/525 [==============================] - 0s 65us/sample - loss: 6.1022\n",
      "Epoch 94/100\n",
      "525/525 [==============================] - 0s 65us/sample - loss: 6.1852\n",
      "Epoch 95/100\n",
      "525/525 [==============================] - 0s 65us/sample - loss: 6.1421\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "525/525 [==============================] - 0s 65us/sample - loss: 6.1342\n",
      "Epoch 97/100\n",
      "525/525 [==============================] - 0s 65us/sample - loss: 6.1455\n",
      "Epoch 98/100\n",
      "525/525 [==============================] - 0s 65us/sample - loss: 6.1521\n",
      "Epoch 99/100\n",
      "525/525 [==============================] - ETA: 0s - loss: 4.988 - 0s 65us/sample - loss: 6.1981\n",
      "Epoch 100/100\n",
      "525/525 [==============================] - 0s 65us/sample - loss: 6.1284\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x28433ae8848>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=20, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I'm using the `X_test` set to obtain the model's prediction. I've also printed out some rows of the predicted minimum and maximum temperatures.\n",
    "\n",
    "**Note:** These are in random order for some random days, (however predictions were still done for consecutive days)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.257655 ,  5.878769 ],\n",
       "       [ 5.2861385, 12.333096 ],\n",
       "       [ 8.784059 , 16.89118  ],\n",
       "       [16.22849  , 23.702333 ],\n",
       "       [17.982056 , 26.115002 ],\n",
       "       [-3.214916 ,  1.6870147],\n",
       "       [ 5.468858 , 13.4878025],\n",
       "       [21.172699 , 31.098381 ],\n",
       "       [ 4.9253774, 15.948999 ],\n",
       "       [ 1.1899122,  5.98812  ]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(X_test)\n",
    "prediction[10:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I'm taking the mean of each row and comparing it to the actual values. Here are some examples of what the Neural Network has predicted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual average temperature | Predicted average temperature\n",
      "----------------------------------------------------------\n",
      "                2.5        |        4.068212\n",
      "               7.25        |        8.809617\n",
      "               14.5        |        12.83762\n",
      "               20.5        |        19.965412\n",
      "              24.05        |        22.048529\n",
      "               -3.5        |        -0.76395065\n",
      "               10.8        |        9.478331\n",
      "              22.25        |        26.13554\n",
      "              12.15        |        10.437188\n",
      "                5.2        |        3.5890162\n"
     ]
    }
   ],
   "source": [
    "prediction_means = np.array([np.mean(e) for e in prediction])\n",
    "actual_means = np.array([np.mean(e) for e in y_test])\n",
    "comparison = [(actual_means[i], prediction_means[i]) for i in range(len(actual_means))][10:20]\n",
    "print('Actual average temperature | Predicted average temperature')\n",
    "print('----------------------------------------------------------')\n",
    "def spaces(l):\n",
    "    return ''.join([' ' for k in range(l)])\n",
    "for i in range(len(comparison)):\n",
    "    c0 = comparison[i][0]\n",
    "    c1 = comparison[i][1]\n",
    "    print(spaces(18-len(str(c0))), c0, spaces(6), \"|\", spaces(6), c1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'd say it works very well for predicting the temperature on the following day.<br><br>\n",
    "We can also take the average of the absolute differences of the actual and predicted values (mean absolute error), to get a feel of how much this predictor misses by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average temperature miss: 1.7174537472229088\n"
     ]
    }
   ],
   "source": [
    "print(\"Average temperature miss:\", np.mean([abs(prediction_means[i] - actual_means[i]) for i in range(len(actual_means))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Predicting multiple days ahead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use the simple model of:\n",
    "1. Predict the minimum and maximum temperatures for the next day.\n",
    "2. Add it to the known values of the model.\n",
    "3. Repeat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this I'll need a fully ordered set of the days and temperatures, so I'll use the original `X` and `y` variables, and not `X_train` and `y_train` that only contain about ~70% of the days in our database.<br>\n",
    "However I'll still use the prevuious `model`.<br><br>\n",
    "The following function creates a continously updating list of the temperatures of the last 12 days (the `last_12_days` variable), calculates a prediction of the next day, appends it to this list, and deletes the first row of `last_12_days`. It does this until it reaches the day we're looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = list(weather['date'])[-1]\n",
    "def predict_temperatures(days_from_now):\n",
    "    predictions = [] \n",
    "    day_needed = today + timedelta(days=days_from_now)\n",
    "    last_12_days = X[-12:]\n",
    "    for i in range(days_from_now):\n",
    "        next_pred = model.predict(last_12_days)[-1]\n",
    "        predictions.append(next_pred)\n",
    "        last_12_days = last_12_days[1:]\n",
    "        last_12_days = np.array(list(last_12_days) + list([np.append(np.append(last_12_days[-1][3:],[day_needed.month]),next_pred)]))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example: These are the predicted temperatures of the following 10 days (October 26th - November 4th):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Day   | Predicted minimum temperature | Predicted maximum temperature\n",
      "-------------------------------------------------------------------------\n",
      "  Oct 26  |           11.423736           |           17.370682\n",
      "  Oct 27  |           10.653222           |           16.565948\n",
      "  Oct 28  |           9.992475            |           16.134771\n",
      "  Oct 29  |           9.569747            |           15.814251\n",
      "  Oct 30  |           9.09143             |           15.583388\n",
      "  Oct 31  |           8.722247            |           15.2616005\n",
      "  Nov 1   |           8.313805            |           14.895863\n",
      "  Nov 2   |           7.8520064           |           14.49543\n",
      "  Nov 3   |           7.3704844           |           14.076249\n",
      "  Nov 4   |           6.9357166           |           13.642221\n"
     ]
    }
   ],
   "source": [
    "next10_pred = predict_temperatures(10)\n",
    "print(\"    Day   | Predicted minimum temperature | Predicted maximum temperature\")\n",
    "print(\"-------------------------------------------------------------------------\")\n",
    "for r in range(len(next10_pred)):\n",
    "    day = today + timedelta(days=r+1)\n",
    "    m = calendar.month_abbr[day.month]\n",
    "    d = day.day\n",
    "    mint = next10_pred[r][0]\n",
    "    maxt = next10_pred[r][1]\n",
    "    print(\" \", m, d, spaces(5-len(str(m))-len(str(d))), \"|\", spaces(9), mint, spaces(18-len(str(mint))), \"|\", spaces(9), maxt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the following function predicts for a specific day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_faraway_day_temperature(year, month, day):\n",
    "    d = date(year, month, day)\n",
    "    today = list(weather['date'])[-1]\n",
    "    delta = (d - date(today.year, today.month, today.day)).days\n",
    "    return predict_temperatures(delta)[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here are the actual predictions the exercise asked for:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted average temperatures in Budapest (°C):\n",
      "------------------------------------------------\n",
      "October 28th: 13.207807\n",
      "November 3rd: 10.723367\n",
      "November 24th: 1.6468673\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted average temperatures in Budapest (°C):\")\n",
    "print(\"------------------------------------------------\")\n",
    "print(\"October 28th:\", np.mean(predict_faraway_day_temperature(2020,10,28)))\n",
    "print(\"November 3rd:\", np.mean(predict_faraway_day_temperature(2020,11,3)))\n",
    "print(\"November 24th:\", np.mean(predict_faraway_day_temperature(2020,11,24)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
